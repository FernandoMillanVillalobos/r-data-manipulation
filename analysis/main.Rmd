---
title: "r-data-manipulation"
author: "Fernando Millan Villalobos"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: show
    echo: TRUE
    warning: FALSE
    message: FALSE
    highlight: pygments
    theme: paper
    df_print: kable
    toc: yes
    toc_depth: 4
    number_sections: yes
    toc_float: 
      collapsed: yes
      smooth_scroll: false
# knit: (function(inputFile, encoding) {
  # rmarkdown::render(inputFile, encoding = encoding, output_dir = "../", output_file = "index") })
# favicon: img/favicon.ico
# url: "https://walker-data.com/census-r"
# cover-image: "04-visualizing-census-data_files/figure-html/visualize-error-bars-1.png"
# description: "This book is an overview of how practitioners can acquire, wrangle, visualize, and model US Census data with the R programming language."
---

```{r, include=FALSE}
## By default, show code for all chunks in the knitted document,
## as well as the output. To override for a particular chunk
## use echo = FALSE in its options.
knitr::opts_chunk$set(
   echo=TRUE, message=FALSE, warning=FALSE
)
```

```{r, echo=FALSE}
# CONFIG
user_name <- "fernandomillanvillalobos" # your Git username (only needed if
# you want to deploy to GH pages)
project_name <- "rddj-template" # adapt!
package_date <- "2022-05-01" # date of the CRAN snapshot that
# the checkpoint package uses
r_version <- "4.2.0" # R-Version to use
options(Ncpus = 4) # use 4 cores for parallelized installation of packages
if (r_version != paste0(version$major, ".", version$minor)) {
  stop("ERROR: specified R version does not match currently used.")
}
```

# Notes

This report was generated on `r Sys.time()`. R version: `r paste0(version$major, ".", version$minor)` on `r version$platform`. For this report, CRAN packages as of `r package_date` were used.

...

## R-Script & data

The preprocessing and analysis of the data was conducted in the [R project for statistical computing](https://www.r-project.org/). The RMarkdown script used to generate this document and all the resulting data can be downloaded [under this link](http://`r user_name`.github.io/`r project_name`/). Through executing `main.Rmd`, the herein described process can be reproduced and this document can be generated. In the course of this, data from the folder `input` will be processed and results will be written to `output`. The html on-line version of the analysis can be accessed through this [link](https://`r user_name`.github.io/`r project_name`/). 

## GitHub

The code for the herein described process can also be freely downloaded from [https://github.com/`r user_name`/`r project_name`](https://github.com/`r user_name`/`r project_name`). 

## License

...

## Data description of output files

#### `abc.csv` (Example)

| Attribute | Type | Description |
|-------|------|-----------------------------------------------------------------------------|
| a | Numeric | ... |
| b | Numeric | ... |
| c | Numeric |  ... |

...

# Set up

```{r, echo=FALSE}
detach_all_packages <- function() {
  basic_packages_blank <-  c("stats",
                             "graphics",
                             "grDevices",
                             "utils",
                             "datasets",
                             "methods",
                             "base")
  basic_packages <- paste("package:", basic_packages_blank, sep = "")

  package_list <- search()[
    ifelse(unlist(gregexpr("package:", search())) == 1, TRUE, FALSE)]

  package_list <- setdiff(package_list, basic_packages)

  if (length(package_list) > 0)  for (package in package_list) {
    detach(package, character.only = TRUE, unload = TRUE)
    print(paste("package ", package, " detached", sep = ""))
  }
}

detach_all_packages()

# this allows multiple persons to use the same RMarkdown
# without adjusting the working directory by themselves all the time
source("scripts/csf.R")
path_to_wd <- csf() # if this - for some reason - does not work,
# replace with a hardcoded path, like so: "~/projects/rddj-template/analysis/"
if (is.null(path_to_wd) | !dir.exists(path_to_wd)) {
  print("WARNING: No working directory specified for current user")
} else {
  setwd(path_to_wd)
}

# suppress scientific notation
options(scipen = 999)

# suppress summarise info
options(dplyr.summarise.inform = FALSE)

# unload global rstudioapi and knitr again to avoid conflicts with checkpoint
# this is only necessary if executed within RStudio
# outside of RStudio, namely in the knit.sh script, this causes RMarkdown
# rendering to fail, thus should not be executed there
if (Sys.getenv("RSTUDIO") == "1") {
  detach_all_packages()
}
```

## Define packages

```{r, echo=TRUE, message=FALSE, warning=FALSE}
# from https://mran.revolutionanalytics.com/web/packages/\
# checkpoint/vignettes/using-checkpoint-with-knitr.html
# if you don't need a package, remove it from here (commenting not sufficient)
# tidyverse: see https://blog.rstudio.org/2016/09/15/tidyverse-1-0-0/
cat("
library(rstudioapi)
library(tidyverse)
library(tidylog)
library(jsonlite)
library(lintr)
library(rmarkdown)
library(rio)
library(cowplot)
library(extrafont)
library(ggrepel)
library(scales)
library(pacman)
library(htmltab)
library(rmiscutils)
library(RSQLite)
library(janitor)",
file = "manifest.R")
```

## Install packages

```{r, echo=TRUE, message=FALSE, warning=FALSE}
# if checkpoint is not yet installed, install it (for people using this
# system for the first time)
if (!require(checkpoint)) {
  if (!require(devtools)) {
    install.packages("devtools", repos = "http://cran.us.r-project.org")
    require(devtools)
  }
  devtools::install_github("RevolutionAnalytics/checkpoint",
                           ref = "v0.3.2", # could be adapted later,
                           # as of now (beginning of July 2017
                           # this is the current release on CRAN)
                           repos = "http://cran.us.r-project.org")
  require(checkpoint)
}
# nolint start
if (!dir.exists("~/.checkpoint")) {
  dir.create("~/.checkpoint")
}
# nolint end
# install packages for the specified CRAN snapshot date
checkpoint(snapshot_date = package_date,
           project = path_to_wd,
           verbose = T,
           scanForPackages = T,
           use.knitr = F,
           R.version = r_version)
rm(package_date)
```

## Load packages

```{r, echo=TRUE, message=FALSE, warning=FALSE}
source("manifest.R")
unlink("manifest.R")
sessionInfo()
```

## Load additional scripts

```{r, echo=TRUE, message=FALSE, warning=FALSE}
# if you want to outsource logic to other script files, see README for 
# further information
# Load all visualizations functions as separate scripts
knitr::read_chunk("scripts/dviz.supp.R")
source("scripts/dviz.supp.R")
knitr::read_chunk("scripts/themes.R")
source("scripts/themes.R")
knitr::read_chunk("scripts/plot_grid.R")
source("scripts/plot_grid.R")
knitr::read_chunk("scripts/align_legend.R")
source("scripts/align_legend.R")
knitr::read_chunk("scripts/label_log10.R")
source("scripts/label_log10.R")
knitr::read_chunk("scripts/outliers.R")
source("scripts/outliers.R")
```

# Import data into R

There are some different ways to do this, depending on how your data is formatted and where it’s located.

## Base-R

### Entering data using R commands

R provides a nice GUI for editing tabular data: __the data editor__.

The `c` function has already been introduced as a way to input small amounts of data into R. When the amount of data is large, and especially when typing the data into the console is inappropriate, the `scan` function can be used. `scan` is most appropriate when all the data to be read is of the same mode, so that it can be accommodated by a vector or matrix. The first argument to `scan` can be a quoted string or character variable containing the name of a file or a URL, or it can be any of a number of connections to allow other input sources. If no first argument is given, scan will read from the console, stopping when a completely blank line is entered. By default, `scan` expects all of its input to be numeric data; this can be overridden with the `what=` argument, which specifies the type of data that scan will see.

When reading from the console, R will prompt you with the index of the next item to be entered, and report on the number of elements read when it’s done. If the what= argument to scan is a list containing examples of the expected data types, scan will output a list with as many elements as there are data types provided. To specify numeric values, you can pass a value of 0.

Note that, by naming the elements in the list passed through the `what=` argument, the output list elements are appropriately named. When the argument to what= is a list, the `multi.line=` option can be set to FALSE to prevent scan from trying to use multiple lines to read the records for an observation. One of the most common uses for scan is to read in data matrices. Since scan returns a vector, a call to scan can be embedded inside a call to the matrix function.

```{r}
salary <- c(18700000, 14626720, 14137500, 13980000, 12916666)
position <- c("QB", "QB", "DE", "QB", "QB")
team <- c("Colts", "Patriots", "Panthers", "Bengals", "Giants")
name.last <- c("Manning", "Brady", "Pepper", "Palmer", "Manning")
name.first <- c("Peyton", "Tom", "Julius", "Carson", "Eli")
top.5.salaries <- data.frame(name.last, name.first, team, position, salary)
top.5.salaries

# calling the built-in data editor
# top.5.salaries <- edit(top.5.salaries)
# fix(top.5.salaries)

# using scan
# names <- scan(what = "")
# names
# names2 = scan(what=list(a=0,b="",c=0))
# names2

# creating a matrix
# mymat <- matrix(scan(), ncol = 3, byrow = TRUE)
# mymat
```

### Importing data from external files

R includes a family of functions for importing delimited text files into R, based on the `read.table` function. The `read.table` function reads a text file into R and returns a data.frame object. Each row in the input file is interpreted as an observation. Each column in the input file represents a variable. The read.table function expects each field to be separated by a delimiter. The most important options are `sep` and `header`. R includes a set of convenience functions that call `read.table` with different default options for these values. Besides that, you can fetch a CSV file from a single URL.

[read.table options](input/img/read.table-options.png)

Although not as common as white-space-, tab-, or comma-separated data, sometimes input data is stored with no delimiters between the values, but with each variable occupying the same columns on each line of input. In cases like this, the `read.fwf` function can be used. The `widths=` argument can be a vector containing the widths of the fields to be read, using negative numbers to indicate columns to be skipped. If the data for each observation occupies more than one line, `widths=` can be a list of as many vectors as there are lines per observation. The `header=`, `row.names=`, and `col.names=` arguments behave similarly to those in `read.table`.

```{r}
snowdata <- read.table("input/BostonWinterSnowfalls.csv", header = TRUE, sep = ",", quote = "\"")

# getting data online
sp500 <- read.csv("http://bit.ly/BostonSnowfallCSV", sep="")

# getting data with no delimiters
ff <- tempfile()
cat(file = ff, "New York, NY 66,834.6 
    Kings, NY 34,722.9 
    Bronx, NY 31,729.8 
    Queens, NY 20,453.0 
    San Francisco, CA 16,526.2 
    Hudson, NJ 12,956.9 
    Suffolk, MA 11,691.6 
    Philadelphia, PA 11,241.1 
    Washington, DC 9,378.0 
    Alexandria IC, VA 8,552.2")
city <- read.fwf(ff, widths = c(18, -19, 8), as.is = TRUE)
city
```
### Exporting data

R can also export R data objects (usually data frames and matrices) as text files. To export data to a text file, use the `write.table` function.There are wrapper functions for `write.table` that call `write.table` with different defaults. These are useful if you want to create a file of comma-separated values.

### Importing data from databases

In order to connect directly to a database from R, you will need to install some optional packages. The packages you need depend on the database(s) to which you want to connect and the connection method you want to use.

There are two sets of database interfaces available in R:

- __RODBC__. The RODBC package allows R to fetch data from ODBC (Open DataBase Connectivity) connections. ODBC provides a standard interface for different programs to connect to databases.

- __DBI__. The DBI package allows R to connect to databases using native database drivers or JDBC drivers. This package provides a common database abstraction for R software.

DBI is not a single package, but instead is a framework and set of packages for accessing databases.One important difference between the DBI packages and the RODBC package is in the objects they use: DBI uses S4 objects to represent drivers, connections, and other objects. To open a connection with DBI, use the dbConnect function. The argument drv can be a DBIDriver object or a character value describing the driver to use. You can generate a DBIDriver object with a call to the DBI driver. The dbConnect function can take additional options, depending on the type of database you are using. For SQLite databases, the most important argument is dbname (which specifies the database file). Check the help files for the database you are using for more options. Even arguments for parameters like usernames are not the same between databases.

As example we can easily copy an R data frame into a SQLite database with dbWriteTable().

```{r}
# to connect with an external database
# drv <- dbDriver("SQLite")
# con <- dbConnect(drv, dbname = system.file("extdata", "bb.db", package = "nutshell"))

# creating our database
mydb <- dbConnect(RSQLite::SQLite(), "")
dbWriteTable(mydb, "mtcars", mtcars)
dbWriteTable(mydb, "iris", iris)
dbListTables(mydb)

# Issue a query with dbGetQuery()
dbGetQuery(mydb, 'SELECT * FROM mtcars LIMIT 5')

# disconnecting from dabase
dbDisconnect(mydb)
```

## Packages
### The magic of rio

“The aim of __rio__ is to make data file I/O [import/output] in R as easy as possible by implementing three simple functions in Swiss-army knife style,” according to the project’s GitHub page. Those functions are `import()`, `export()`, and `convert()`. So, the rio package has just one function to read in many different types of files: `import()`. Once you’ve analyzed your data, if you want to save the results as a CSV, Excel spreadsheet, or other format, rio’s `export()` function can handle that. You can use R’s `download.file` function with the syntax `download.file("url", "destinationFileName.csv")` to download files directly from the web. It’s possible rio will ask you to re-download the file in binary format, in which case you’ll need to run `download.file(“http://bit.ly/BostonSnowfallCSV”, “BostonWinterSnowfalls.csv”, mode=‘wb’`).

```{r}
# getting data from the web with R-built-in
download.file("http://bit.ly/BostonSnowfallCSV", "input/BostonWinterSnowfalls.csv")
# download.file(“http://bit.ly/BostonSnowfallCSV”, “BostonWinterSnowfalls.csv”, mode=‘wb’)

# import data with rio locally
snowdata2 <- rio::import("input/BostonWinterSnowfalls.csv")
suicides <- rio::import("input/PDT-suicidesData.csv")
# rio::import("mySpreadsheet.xlsx", which = 2, col_names = c("City", "State", "Population"))
```

#### Import a file from the Web 

If you want to download and import a file from the Web, you can do so if it’s publicly available and in a format such as Excel or CSV you can use `rio`. A lot of systems will be able to follow the redirect URL to the file even after first giving you an error message, as long as you specify the format as “csv” since the file name here doesn’t include “.csv”. rio can also import well-formatted HTML tables from Web pages, but the tables have to be extremely well-formatted. In real life, though, Web data rarely appears in such neat, isolated form. A good option for cases that aren’t quite as well crafted is often the __htmltab__ package. Since it wasn't specified which table, it pulled the first HTML table on the page. To download a specific table use the `which` argument.

The most popular way to install packages from GitHub is to use a package called __devtools__. devtools is an extremely powerful package designed mostly for people who want to write their own packages, and it includes a few ways to install packages from other places besides CRAN. However, devtools usually requires a couple of extra steps to install compared to a typical package. However, the __pacman__ package will also install packages from non-CRAN sources like GitHub. You can use the `number_with_commas()` function to change those character strings that should be numbers back into numbers. The __rmiscutils__ package isn’t the only way to deal with imported numbers that have commas, the tidyverse readr package also includes a function that turns character strings into numbers, `parse_number()`. One advantage of `readr::parse_number()` is that you can define your own `locale()` to control things like encoding and decimal marks. There’s an R package called __janitor__ that can automatically fix troublesome column names imported from a non-R-friendly data source. You can create new clean column names using janitor’s `clean_names()` function.

```{r}
# getting data from the web with rio
snowdata3 <- rio::import("http://bit.ly/BostonSnowfallCSV", format = "csv")

# getting html tables
design.tokens1 <- rio::import("https://designsystem.digital.gov/design-tokens/", format = "html")
citytable <- htmltab("https://en.wikipedia.org/wiki/List_of_United_States_cities_by_population", which = 5)
design.tokens2 <- htmltab("https://designsystem.digital.gov/design-tokens/", which = 6)

# installing packages from GitHub with pacman
pacman::p_load_gh("smach/rmiscutils")

# changing those character strings that should be numbers back into numbersC
citytable$PopEst2021 <- number_with_commas(citytable$`2021estimate`)
citytable$Census2020 <- readr::parse_number(citytable$`2020census`)

# cleaning cols names
citytable_cleaned <- janitor::clean_names(citytable)
names(citytable_cleaned)
```

#### Import data from packages

If you are interested in state or local government data in the US or Canada, you may want to check out RSocrata to see if an agency you’re interested in posts data there. I’ve yet to find a complete list of all available Socrata data sets, but there’s a search page at https://www.opendatanetwork.com.

### What’s a data frame? And what can you do with one?

It’s easy to add a column to a data frame. The name of the new column is on the left, and there’s a formula on the right. Some of these special dataframe functions (technically called “methods”) not only give you information, but let you change characteristics of the data frame. So, `names(snowdata)` tells you the column names in the data frame but it will change the column names in the data frame.

```{r}
# adding cols
snowdata$Meters <- snowdata$Total * 0.0254

# changing col names
names(snowdata) <- c("Winter", "SnowInches", "SnowMeters")

# changing from num to chr
download.file("https://raw.githubusercontent.com/smach/R4JournalismBook/master/data/bostonzips.txt", "input/bostonzips.txt")
zips <- rio::import("input/bostonzips.txt", colClasses = c("character", "character"))
# or
# zips <- rio::import("input/bostonzips.txt", colClasses = rep("character", 2))
# rep("character", 2) is the same as c(“character”, “character”), so colClasses = rep("character", 2) is equivalent to colClasses = c("character", "character")
```

### Exporting data

Often after you’ve wrangled your data in R, you’ll want to save your results. Here are some of the ways to export your data:

- Save to a CSV file with `rio::export(myObjectName, file="myFileName.csv")` and to an Excel file with `rio::export(myObjectName, file="myFileName.xlsx")`. rio understands what file format you want based on the extension of the file name. There are several other available formats, including .tsv for tab-separated data, .json for JSON and .xml for XML.

- Save to an R binary object that makes it easy to load back into R in future sessions. There are two options.

Generic `save()` will save one or more objects into a file, such as `save(objectName1, objectName2, file="myfilename.RData")`. To read this data back into R, you just use the command `load("myfilename.RData")` and all the objects return with the same names in the same state they had before.

You can also save a single object into a file with `saveRDS(myobject, file="filename.rds")`. The logical assumption would be that loadRDS would read the file back in, but instead the command is readRDS – and in this case, just the data has been stored, not the object name. So, you need to read the data into a new object name, such as `mydata <- readRDS("filename.rds")`.

You can also export an R object into your Windows or Mac clipboard with rio: `rio::export(myObjectName, format = "clipboard")`. And, you can import data into R from your clipboard the same way: `rio::import(file = "clipboard")`.

rio’s `convert()` function lets you convert one file type to another without having to manually pull the data into and then out of R.

### Additional resources

While rio is a great Swiss Army knife of file handling, there may be times when you want a bit more control over how your data is pulled into or saved out of R. In addition, there have been times when I’ve had a challenging data file that rio choked on but another package could handle. Some other functions and packages you may want to explore:

- Base R’s `read.csv()` and `read.table()` to import text files (use ?read.csv and ?read.table to get more information). `stringsAsFactors = FALSE` is needed with these if you want to keep your character strings as character strings. `write.csv()` will save to CSV.

- Wickham’s readr package is also worth a look as part of the “tidyverse.” __readr__ includes functions to read CSV, tab-separated, fixed-width, Web logs, and several other types of files. readr prints out the type of data it has determined for each column – integer, character, double (non-whole numbers), etc. It creates tibbles.

- The __googlesheets__ package lets you import data from a Google Sheet, even if it’s private, by authenticating your Google account. The package is available on CRAN; install it with with `install.packages("googlesheets")`.

If you are working with large data sets, speed may become important to you when saving and loading files. The __data.table__ package has a speedy `fread()` function, but beware that resulting objects are data.tables and not plain data frames; some behaviors are different. If you want a conventional data frame, you can get one with the `as.data.frame(mydatatable)` syntax. `fwrite()` function is aimed at writing to a CSV file considerably faster than base R’s `write.csv()`.

The __feather__ package saves in a binary format that can be read either into R or Python. And, the __fst__ package’s `read.fst()` and `write.fst()` offer fast saving and loading of R data frame objects – plus the option of file compression.

# Linting

The code in this RMarkdown is linted with the [lintr package](https://github.com/jimhester/lintr), which is based on the  [tidyverse style guide](http://style.tidyverse.org/). 

```{r echo=TRUE, message=FALSE, warning=FALSE, results='hide'}
# lintr::lint("main.Rmd", linters =
#               lintr::with_defaults(
#                 commented_code_linter = NULL,
#                 trailing_whitespace_linter = NULL
#                 )
#             )
# if you have additional scripts and want them to be linted too, add them here
# lintr::lint("scripts/my_script.R")
```
